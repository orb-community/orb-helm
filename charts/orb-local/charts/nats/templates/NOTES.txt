** Please be patient while the chart is being deployed **

{{- if .Values.diagnosticMode.enabled }}
The chart has been deployed in diagnostic mode. All probes have been disabled and the command has been overwritten with:

  command: {{- include "common.tplvalues.render" (dict "value" .Values.diagnosticMode.command "context" $) | nindent 4 }}
  args: {{- include "common.tplvalues.render" (dict "value" .Values.diagnosticMode.args "context" $) | nindent 4 }}

Get the list of pods by executing:

  kubectl get pods --namespace {{ .Release.Namespace }} -l app.kubernetes.io/instance={{ .Release.Name }}

Access the pod you want to debug by executing

  kubectl exec --namespace {{ .Release.Namespace }} -ti <NAME OF THE POD> -- bash

In order to replicate the container startup scripts execute this command:

    /opt/bitnami/scripts/nats/entrypoint.sh

{{- else }}

{{- if or (contains .Values.client.service.type "LoadBalancer") (contains .Values.client.service.type "nodePort") }}
{{- if not .Values.auth.enabled }}
{{ if and (not .Values.networkPolicy.enabled) (.Values.networkPolicy.allowExternal) }}

-------------------------------------------------------------------------------
 WARNING

    By specifying "client.service.type=NodePort/LoadBalancer" and "auth.enabled=false"
    you have most likely exposed the NATS service externally without any authentication
    mechanism.

    For security reasons, we strongly suggest that you switch to "ClusterIP". As
    alternative, you can also switch to "auth.enabled=true" providing a valid
    password on "auth.password" parameter.

-------------------------------------------------------------------------------
{{- end }}
{{- end }}
{{- end }}

NATS can be accessed via port {{ .Values.client.service.port }} on the following DNS name from within your cluster:

   {{ template "common.names.fullname" . }}-client.{{ .Release.Namespace }}.svc.cluster.local

{{- if .Values.auth.enabled }}

To get the authentication credentials, run:

    export NATS_USER=$(kubectl get cm --namespace {{ .Release.Namespace }} {{ template "common.names.fullname" . }} -o jsonpath='{.data.*}' | grep -m 1 user | awk '{print $2}' | tr -d '"')
    export NATS_PASS=$(kubectl get cm --namespace {{ .Release.Namespace }} {{ template "common.names.fullname" . }} -o jsonpath='{.data.*}' | grep -m 1 password | awk '{print $2}' | tr -d '"')
    echo -e "Client credentials:\n\tUser: $NATS_USER\n\tPassword: $NATS_PASS"

{{- end }}

NATS monitoring service can be accessed via port {{ .Values.monitoring.service.port }} on the following DNS name from within your cluster:

    {{ template "common.names.fullname" . }}-monitoring.{{ .Release.Namespace }}.svc.cluster.local

You can create a Golang pod to be used as a NATS client:

      kubectl run {{ include "common.names.fullname" . }}-client --restart='Never' --image docker.io/bitnami/golang --namespace {{ .Release.Namespace }} --command -- sleep infinity
      kubectl exec --tty -i {{ include "common.names.fullname" . }}-client --namespace {{ .Release.Namespace }} -- bash
      GO111MODULE=off go get github.com/nats-io/nats.go
      cd $GOPATH/src/github.com/nats-io/nats.go/examples/nats-pub && go install && cd
      cd $GOPATH/src/github.com/nats-io/nats.go/examples/nats-echo && go install && cd
      {{- if .Values.auth.enabled }}
      nats-echo -s nats://NATS_USER:NATS_PASS@{{ template "common.names.fullname" . }}-client.{{ .Release.Namespace }}.svc.cluster.local:{{ .Values.client.service.port }} SomeSubject
      nats-pub -s nats://NATS_USER:NATS_PASS@{{ template "common.names.fullname" . }}-client.{{ .Release.Namespace }}.svc.cluster.local:{{ .Values.client.service.port }} -reply Hi SomeSubject "Hi everyone"
      {{- else }}
      nats-echo -s nats://{{ template "common.names.fullname" . }}-client.{{ .Release.Namespace }}.svc.cluster.local:{{ .Values.client.service.port }} SomeSubject
      nats-pub -s nats://{{ template "common.names.fullname" . }}-client.{{ .Release.Namespace }}.svc.cluster.local:{{ .Values.client.service.port }} -reply Hi SomeSubject "Hi everyone"
      {{- end }}

To access the Monitoring svc from outside the cluster, follow the steps below:

{{- if .Values.ingress.enabled }}

1. Get the hostname indicated on the Ingress Rule and associate it to your cluster external IP:

    export CLUSTER_IP=$(minikube ip) # On Minikube. Use: `kubectl cluster-info` on others K8s clusters
    echo "Monitoring URL: http{{ if .Values.ingress.tls }}s{{ end }}://{{ .Values.ingress.hostname }}"
    echo "$CLUSTER_IP  {{ .Values.ingress.hostname }}" | sudo tee -a /etc/hosts

{{- else }}

1. Get the NATS monitoring URL by running:

{{- if contains "NodePort" .Values.monitoring.service.type }}

    export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
    export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ printf "%s-monitoring" (include "common.names.fullname" .) }})
    echo "Monitoring URL: http://$NODE_IP:$NODE_PORT/"

{{- else if contains "LoadBalancer" .Values.monitoring.service.type }}

    NOTE: It may take a few minutes for the LoadBalancer IP to be available.
        Watch the status with: 'kubectl get svc --namespace {{ .Release.Namespace }} -w {{ printf "%s-monitoring" (include "common.names.fullname" .) }}'

    export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ printf "%s-monitoring" (include "common.names.fullname" .) }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
    echo "Monitoring URL: http://$SERVICE_IP/"

{{- else if contains "ClusterIP" .Values.monitoring.service.type }}

    echo "Monitoring URL: http://127.0.0.1:{{ .Values.monitoring.service.port }}"
    kubectl port-forward --namespace {{ .Release.Namespace }} svc/{{ printf "%s-monitoring" (include "common.names.fullname" .) }} {{ .Values.monitoring.service.port }}:{{ .Values.monitoring.service.port }}
{{- end }}
{{- end }}

2. Open a browser and access the NATS monitoring browsing to the Monitoring URL


{{- if .Values.metrics.enabled }}

3. Get the NATS Prometheus Metrics URL by running:

    echo "Prometheus Metrics URL: http://127.0.0.1:{{ .Values.metrics.service.port }}/metrics"
    kubectl port-forward --namespace {{ .Release.Namespace }} svc/{{ printf "%s-metrics" (include "common.names.fullname" .) }} {{ .Values.metrics.service.port }}:{{ .Values.metrics.service.port }}

4. Access NATS Prometheus metrics by opening the URL obtained in a browser.

{{- end }}
{{- end }}

{{- include "nats.validateValues" . -}}
{{- include "nats.checkRollingTags" . -}}
